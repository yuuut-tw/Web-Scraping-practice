{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=\"black\">**任務流程**</font>\n",
    "1. 前置作業 ＝> import 需要套件、建立相關身份認證資料\n",
    "2. 打開開發人員工具，找到搜尋html，使用selenium輸入關鍵字搜尋，並進入搜尋結果頁面（詳情：selenium-dcard應用），104為動態網頁，使用selenium進行頁面滑動，依個人需求取得各職缺網址，並存成一個網址list\n",
    "4. 透過迴圈進入各職缺網址內，取得相關資料，append進入output_list中，後續將此list轉成df\n",
    "5. 將爬蟲回來的資料存成df，進行data cleaning，完成後輸出為excel檔！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "參考資料:\n",
    "<br>\n",
    "1. [104人力銀行 網路爬蟲](https://tlyu0419.github.io/2020/06/19/Crawler-104HumanResource/)\n",
    "<br>\n",
    "2. [[網頁爬蟲] 104人力銀行標籤抓不到內容](https://ithelp.ithome.com.tw/questions/10198403)\n",
    "<br>\n",
    "3. [Python 使用 Beautiful Soup 抓取與解析網頁資料，開發網路爬蟲教學](https://blog.gtwang.org/programming/python-beautiful-soup-module-scrape-web-pages-tutorial/2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前置作業 ＝> import 需要套件、建立headers&相關cookies資料\n",
    "1. 設置optins => 擋掉跳出視窗\n",
    "2. 建立headers\n",
    "3. 準備參數cookies (全職、關鍵字、清單條例式)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:17:58.979564Z",
     "start_time": "2021-05-27T06:17:58.229773Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:18:00.590939Z",
     "start_time": "2021-05-27T06:18:00.583955Z"
    }
   },
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--disable-notifications\")\n",
    "\n",
    "url_search = \"https://104.com.tw/jobs/search/?\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36'}\n",
    "my_params = {'ro': '1',                # 限定全職的工作，如果不限定則輸入0\n",
    "             'keyword': '數據分析',     # 想要查詢的關鍵字\n",
    "             'mode': 'l'}              # 清單瀏覽模式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打開開發人員工具，找到搜尋html，使用selenium輸入關鍵字搜尋，並進入搜尋結果頁面\n",
    "\n",
    "1. session連線 => 帶著my_params通過搜尋頁面，抵達搜尋結果頁面，104為動態網頁，使用selenium進行頁面滑動\n",
    "2. 輸入欲爬取至第幾頁面\n",
    "3. 建立url的beautiful soup物件，取得各職缺網址並存成work_url_lists\n",
    "    - 使用**driver.page_source**來取得所有頁面資訊\n",
    "    - 過濾掉置頂徵才廣告 => url中jobsource參數等於hotjob_chr者\n",
    "    - 取得url中的職缺編號，並組成app版網址 =>　https://m.104.com.tw/job/ + 職缺編號(ex. 5944x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:18:48.381505Z",
     "start_time": "2021-05-27T06:18:05.135232Z"
    }
   },
   "outputs": [],
   "source": [
    "# session 連線\n",
    "# 帶著參數通過搜尋頁面，抵達結果頁面的網址\n",
    "ss = requests.session()\n",
    "res = ss.get(url_search, headers=headers, params=my_params)\n",
    "\n",
    "# 104為動態網頁，使用selenium進行頁面滑動，蒐集網址\n",
    "# 輸入欲爬取至第幾頁面\n",
    "page_number = int(input(\"請輸入欲爬取至第幾頁面: \"))\n",
    "driver = Chrome(\"../../chromedriver\", options=options)\n",
    "driver.get(res.url)\n",
    "for i in range(1, page_number+1):\n",
    "    driver.execute_script(\"var s = document.documentElement.scrollTop=5000\")\n",
    "    print(\"目前爬至第{}頁\".format(i))\n",
    "    time.sleep(5)\n",
    "\n",
    "# 建立beautiful soup物件\n",
    "# 使用driver.page_source來取得所有頁面資訊\n",
    "# 過濾掉置頂徵才廣告 => url中包含hotjob_chr參數\n",
    "# 取得url中的職缺編號，並組成手機版網址 =>　https://m.104.com.tw/job/ + 職缺編號(ex. 5944x)\n",
    "soup = BeautifulSoup(driver.page_source, features='html.parser')\n",
    "url_data = [url[\"href\"] for url in soup.select('li.job-mode__jobname a') if url[\"href\"].split(\"=\")[1] != 'hotjob_chr']\n",
    "work_url_lists = list(map(lambda url: 'https://m.104.com.tw/job/{}'.format(re.findall(\"job/(.*)\\?\", url)[0]), url_data))\n",
    "\n",
    "# 關閉頁面\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(work_url_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 透過迴圈進入各職缺網址內，取得相關資料，append進入output中，後續將此轉成df\n",
    "1. 每3秒爬一次，避免被鎖ip或是重導到電腦版網址，因而產生錯誤\n",
    "2. 取得職缺相關資料\n",
    "    - 更新時間、公司、職位、工作地點、工作內容\n",
    "    - 工作需求技能、工具、其他條件\n",
    "    - 額外資訊(聯絡人、薪水)\n",
    "5. append進入output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T07:43:41.007587Z",
     "start_time": "2021-05-27T07:43:40.416536Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 每3秒爬一次，避免被鎖或是導向網頁，造成錯誤發生\n",
    "output = []\n",
    "for work_url in work_url_lists:\n",
    "    print(work_url)\n",
    "    res_work = ss.get(work_url, headers=headers, allow_redirects=False)\n",
    "    w_soup = BeautifulSoup(res_work.text, 'html.parser')\n",
    "    \n",
    "    try:\n",
    "        # 更新時間、公司、職位、工作地點、工作內容\n",
    "        update_time = w_soup.select(\"time\")[0]['datetime']\n",
    "        company = w_soup.select('h2.company')[0].text\n",
    "        title = w_soup.select('h1.title')[0].text\n",
    "        work_place = w_soup.select('div.content a.addr')[0].text.strip()\n",
    "        description = w_soup.select(\"div.content p\")[0].text.strip()\n",
    "        \n",
    "        # 工作需求技能、工具、其他條件\n",
    "        job_skill = \" \".join([i.text for i in w_soup.select(\"a[data-gtm='job-skill']\")])\n",
    "        job_tool = \" \".join([i.text for i in w_soup.select(\"a[data-gtm='job-tool']\")])\n",
    "        if w_soup.select(\"td div.cut\"):\n",
    "            plus = w_soup.select(\"td div.cut\")[0].text\n",
    "        else:\n",
    "            plus = \"\"\n",
    "        \n",
    "        ### 額外資訊(聯絡人、薪水)\n",
    "        recruiter = w_soup.find_all(\"table\", class_=\"column2 contact\")[0].select(\"td\")[0].text\n",
    "        extra_data = ''.join([t.text for t in w_soup.select(\"table.column2 td\")])\n",
    "        salary = re.findall(r\"待遇面議.*|[年月]薪.*[元以上]\", extra_data) \n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(\"Value error\", work_url)\n",
    "    except IndexError as e:\n",
    "        print(\"Index error\", work_url)\n",
    "        \n",
    "    output.append([update_time, company, title, work_place, salary, description, job_skill, job_tool, plus, recruiter, work_url])\n",
    "    \n",
    "    time.sleep(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將爬蟲回來的資料存成df，進行data cleaning\n",
    "1. 設置欄位\n",
    "2. 去除重複值 => 透過company, title, work_place來篩選，保留第一個(日期較新)\n",
    "3. 建立將df備份成df2，避免資料處理中不小心改動到原檔因而得重新來過"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:30.142148Z",
     "start_time": "2021-05-27T06:30:30.118144Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(output, columns=['update_time', 'company', 'title', 'work_place', 'salary', 'description', 'job_skill', 'job_tool', \"plus\", \"recruiter\", \"URL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:31.685496Z",
     "start_time": "2021-05-27T06:30:31.660833Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:32.541021Z",
     "start_time": "2021-05-27T06:30:32.528055Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 去除重複值 => 透過company, title, work_place來篩選掉相同重複值缺，保留第一個(日期較新)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:34.240642Z",
     "start_time": "2021-05-27T06:30:34.133907Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.drop_duplicates(subset=['company', 'title', 'work_place'], keep=\"first\", inplace=True)\n",
    "df2.sort_values(by=\"update_time\", ascending=False, inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T09:03:17.435316Z",
     "start_time": "2021-05-26T09:03:17.351414Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 薪資(salary)\n",
    "將薪資進行統一格式處理\n",
    "- 分成下限 & 上限 => 以利後續查找資料\n",
    "- 年薪改為月薪 => 除以12\n",
    "- 待遇面議改為下限4w、上限面議\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:36.253420Z",
     "start_time": "2021-05-27T06:30:36.234463Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2[\"salary\"] = df2[\"salary\"].apply(lambda x: re.sub(\" \", \"\", x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:37.116049Z",
     "start_time": "2021-05-27T06:30:37.088123Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.loc[(df2[\"salary\"].str.contains(\"待遇面議\")), \"salary\"] = \"40000~0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:38.053821Z",
     "start_time": "2021-05-27T06:30:38.040347Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"salary\"] = df2[\"salary\"].apply(lambda x: re.sub(\",|[^0-9~]\", \"\", x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:38.771596Z",
     "start_time": "2021-05-27T06:30:38.740677Z"
    }
   },
   "outputs": [],
   "source": [
    "# 有些只寫起薪的會造成error，index用-1避免報錯\n",
    "df2[\"salary_min\"] = df2[\"salary\"].map(lambda x: x.split(\"~\")[0])\n",
    "df2[\"salary_max\"] = df2[\"salary\"].map(lambda x: x.split(\"~\")[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:40.051167Z",
     "start_time": "2021-05-27T06:30:40.008281Z"
    }
   },
   "outputs": [],
   "source": [
    "# data type轉成 numeric\n",
    "df2[[\"salary_min\", \"salary_max\"]] = df2[[\"salary_min\", \"salary_max\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:40.889668Z",
     "start_time": "2021-05-27T06:30:40.856203Z"
    }
   },
   "outputs": [],
   "source": [
    "## 年薪改為月薪 => 此處用平均數加上3倍標準差來過濾出極端值後進行處理，應該有更好的方法\n",
    "cond_low = df2[\"salary_min\"].mean() + 3*df2[\"salary_min\"].std()\n",
    "cond_upper = df2[\"salary_max\"].mean() + 3*df2[\"salary_max\"].std()\n",
    "\n",
    "df2[\"salary_min\"] = df2[\"salary_min\"].apply(lambda x: int(x/12) if x > cond_low else x)\n",
    "df2[\"salary_max\"] = df2[\"salary_max\"].apply(lambda x:int(x/12) if x >cond_upper else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:41.904403Z",
     "start_time": "2021-05-27T06:30:41.891437Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 只寫起薪或salary_max等於0者，設定為\"面議\"\n",
    "df2.loc[(df2[\"salary_min\"] == df2[\"salary_max\"]) | (df2[\"salary_max\"] == 0), \"salary_max\"] = \"面議\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:42.729751Z",
     "start_time": "2021-05-27T06:30:42.691208Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T09:36:17.310946Z",
     "start_time": "2021-05-26T09:36:17.279123Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 地區\n",
    "1. 去除所有空格\n",
    "2. 從work_place中分成出area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:44.428835Z",
     "start_time": "2021-05-27T06:30:44.422851Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"work_place\"] = df2[\"work_place\"].apply(lambda x: re.sub(\" \", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:45.227412Z",
     "start_time": "2021-05-27T06:30:45.209461Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"area\"] = df2[\"work_place\"].str.strip().str[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:46.086717Z",
     "start_time": "2021-05-27T06:30:46.071098Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"work_place\"] = df2[\"work_place\"].str.strip().str[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 處理job_skill 、 job_tool\n",
    "\n",
    "- 為空值者，設為不拘 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:49.938084Z",
     "start_time": "2021-05-27T06:30:49.909637Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.loc[(df2[\"job_tool\"] == \"\") | (df2[\"job_skill\"] == \"\"), [\"job_skill\", \"job_tool\"]] = \"不拘\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其他條件(plus)、工作內容(description) => 除去任何空白字符\n",
    "- 其他條件(plus)為空白者，設為無"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:53.993437Z",
     "start_time": "2021-05-27T06:30:53.971469Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"plus\"] = df2[\"plus\"].apply(lambda x: re.sub(r\"\\s\", \"\", x)) ## r\"\\s\" => r\"\"表示此字串套用re規則，\\s代表匹配任何空白字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:51.032426Z",
     "start_time": "2021-05-27T06:30:51.007496Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.loc[(df2[\"plus\"] == \"\"), \"plus\"] = \"無\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:54.835762Z",
     "start_time": "2021-05-27T06:30:54.818806Z"
    }
   },
   "outputs": [],
   "source": [
    "df2[\"description\"] = df2[\"description\"].apply(lambda x: re.sub(r\"\\s\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T15:38:05.744340Z",
     "start_time": "2021-05-26T15:38:05.659453Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重新排序columns\n",
    "\n",
    "- 欄位重新排為以下順序 => 'update_time', 'company', 'title', 'area', 'work_place', 'salary_min', 'salary_max', 'description', 'job_skill', 'job_tool', 'plus', 'recruiter', 'URL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:30:58.080332Z",
     "start_time": "2021-05-27T06:30:58.059171Z"
    }
   },
   "outputs": [],
   "source": [
    "col = list(df2.columns)\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:46:36.767944Z",
     "start_time": "2021-05-27T06:46:36.747476Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df2[col[:3] + [col[-1]] + [col[3]] + col[-3:-1] + col[5:-3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:46:42.591712Z",
     "start_time": "2021-05-27T06:46:42.539795Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重設index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:46:40.026093Z",
     "start_time": "2021-05-27T06:46:40.016121Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 存成excel檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T06:47:02.104876Z",
     "start_time": "2021-05-27T06:47:01.809037Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.to_excel(\"./104_job_bank(data analysis related).xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T15:22:49.711475Z",
     "start_time": "2021-05-26T15:22:49.659216Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
